<!doctype html><html lang=en><head><meta charset=utf-8><title>Jay Vala</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="The misterious $k$"><meta property="og:title" content="Finding K in K-Means"><meta property="og:description" content="The misterious $k$"><meta property="og:type" content="website"><meta property="og:url" content="https://jdvala.github.io/posts/2018-07-09-k-means-clusturing/"><meta itemprop=name content="Finding K in K-Means"><meta itemprop=description content="The misterious $k$"><meta name=twitter:card content="summary"><meta name=twitter:title content="Finding K in K-Means"><meta name=twitter:description content="The misterious $k$"><link rel=apple-touch-icon sizes=180x180 href=apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=favicon-32.png><link rel=stylesheet href=https://jdvala.github.io/scss/style.min.d1aa507e320f63a9a89fb4d16c025955cea1564900de1060a4b2d7cabbabcdec.css></head><body><header><div class="header header-frame"><div><h1 class=header__title>Finding K in K-Means</h1><div class=header__description>The misterious $k$</div></div><nav class=header-nav><ul class="header-nav-list header-nav-list--menu"><li class=header-nav-list__item><a class=header-nav-list__link href=/about/><span>About</span></a></li></ul><button class=header-nav-list__nav-btn>navigation</button></nav><button class=mb-header__menu-btn>
<span class=mb-header__menu-btn-line></span>
<span class=mb-header__menu-btn-line></span>
<span class=mb-header__menu-btn-line></span></button></div><nav id=mobile-header-nav class=mb-header-nav><button class="mb-header-nav__close-btn flex-center"><svg class="mb-header-nav__svg-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="32" height="32"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/><path d="M0 0h24v24H0z" fill="none"/></svg></button><div class=mb-header-nav__wrapper><div class=mb-header-nav__container><svg width="240" height="72" viewBox="0 0 240 72" class="mb-header-nav__title"><text x="50%" y="50%" dominant-baseline="middle" text-anchor="middle">Tags</text></svg><ul class=mb-header-nav-list><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/python/>python</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/text/>text</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/dataset/>dataset</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/nlp/>nlp</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/analysis/>analysis</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/kmeans/>kmeans</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/clustering/>clustering</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/findk/>findk</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/silhouette-analysis/>silhouette-analysis</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/elbow-analysis/>elbow-analysis</a></li></ul></div><div class=mb-header-nav__container><svg width="240" height="72" viewBox="0 0 240 72" class="mb-header-nav__title"><text x="50%" y="50%" dominant-baseline="middle" text-anchor="middle">Menu</text></svg><ul class=mb-header-nav-list><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=/about/>About</a></li></ul></div></div></nav></header><div id=content><article class=post><div class=post-content><h1 id=finding-k-in-k-means>Finding K in K-Means</h1><p>So when applying K-Means Clustring, one comes at a point where he/she has to decide how many cluster they want, now one can not go and tell 2,3, or 4 clusters there should be a some evidence that clustering the data into <em>&lsquo;k&rsquo;</em> clusters will yeild good results. So I met this problem, after searching for what can be done about this problem I stumble upon a something called <strong>&lsquo;Silhouette Analysis&rsquo;</strong></p><h3 id=silhouette-analysis>Silhouette Analysis</h3><p>Silhouette Analysis takes into considration of how well a particular data point lies within a given cluster. So lets take an example to understand how this works, Say we are using K-Means Clustring for <em>&lsquo;k&rsquo;</em> number of clusters. Now for a data point <em>&lsquo;i&rsquo;</em>, we define average distance from all points in the same cluster as <em>avg(i) = a(i)</em>, so we can interpret <em>a(i)</em> as measure of how well that point belongs in the cluster or to put it simply how well that point belongs in that cluster, so smaller the value, better the assignment of that data point to that cluster. Similarly, lets say <em>b(i)</em> is the average dissimlarity, that means <em>b(i)</em> the lowest average distance of data point <em>i</em> to all points in any other cluster, of which <em>i</em> is not a member of. The cluster with this lowest average dissimilarity is said to be the &ldquo;neighbouring cluster&rdquo; of <em>i</em> because it is the next best fit cluster for point <em>i</em></p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>IPython.display</span> <span style=color:#000;font-weight:700>import</span> Math
</span></span><span style=display:flex><span>Math(<span style=color:#d14>r</span><span style=color:#d14>&#39;s(i) = \frac{b(i)-a(i)}{max(b(i),a(i))}&#39;</span>)
</span></span></code></pre></div><p>$$s(i) = \frac{b(i)-a(i)}{max(b(i),a(i))}$$</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>sklearn.feature_extraction.text</span> <span style=color:#000;font-weight:700>import</span> CountVectorizer
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>sklearn.feature_extraction.text</span> <span style=color:#000;font-weight:700>import</span> TfidfVectorizer
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>sklearn.cluster</span> <span style=color:#000;font-weight:700>import</span> KMeans
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>sklearn.metrics</span> <span style=color:#000;font-weight:700>import</span> silhouette_samples, silhouette_score
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#998;font-style:italic># Getting all the english and german data</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>os</span><span style=color:#000;font-weight:700>,</span> <span style=color:#555>re</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>label <span style=color:#000;font-weight:700>=</span> []
</span></span><span style=display:flex><span>content <span style=color:#000;font-weight:700>=</span> []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>for</span> root, dirs, files <span style=color:#000;font-weight:700>in</span> os<span style=color:#000;font-weight:700>.</span>walk(<span style=color:#d14>&#39;/home/jay/Data/English/&#39;</span>):
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>for</span> file <span style=color:#000;font-weight:700>in</span> files:
</span></span><span style=display:flex><span>        topic <span style=color:#000;font-weight:700>=</span> root<span style=color:#000;font-weight:700>.</span>split(os<span style=color:#000;font-weight:700>.</span>path<span style=color:#000;font-weight:700>.</span>sep)[<span style=color:#000;font-weight:700>-</span><span style=color:#099>2</span>]
</span></span><span style=display:flex><span>        <span style=color:#000;font-weight:700>if</span> file<span style=color:#000;font-weight:700>.</span>endswith(<span style=color:#d14>&#39;.txt&#39;</span>) <span style=color:#000;font-weight:700>and</span> file <span style=color:#000;font-weight:700>!=</span> <span style=color:#d14>&#39;log.txt&#39;</span>:
</span></span><span style=display:flex><span>            <span style=color:#000;font-weight:700>with</span> <span style=color:#0086b3>open</span>(os<span style=color:#000;font-weight:700>.</span>path<span style=color:#000;font-weight:700>.</span>join(root, file)) <span style=color:#000;font-weight:700>as</span> f:
</span></span><span style=display:flex><span>                content<span style=color:#000;font-weight:700>.</span>append(f<span style=color:#000;font-weight:700>.</span>read())
</span></span><span style=display:flex><span>                label<span style=color:#000;font-weight:700>.</span>append(topic)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>for</span> root, dirs, files <span style=color:#000;font-weight:700>in</span> os<span style=color:#000;font-weight:700>.</span>walk(<span style=color:#d14>&#39;/home/jay/Data/German/&#39;</span>):
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>for</span> file <span style=color:#000;font-weight:700>in</span> files:
</span></span><span style=display:flex><span>        topic <span style=color:#000;font-weight:700>=</span> root<span style=color:#000;font-weight:700>.</span>split(os<span style=color:#000;font-weight:700>.</span>path<span style=color:#000;font-weight:700>.</span>sep)[<span style=color:#000;font-weight:700>-</span><span style=color:#099>2</span>]
</span></span><span style=display:flex><span>        <span style=color:#000;font-weight:700>if</span> file<span style=color:#000;font-weight:700>.</span>endswith(<span style=color:#d14>&#39;.txt&#39;</span>) <span style=color:#000;font-weight:700>and</span> file <span style=color:#000;font-weight:700>!=</span> <span style=color:#d14>&#39;log.txt&#39;</span>:
</span></span><span style=display:flex><span>            <span style=color:#000;font-weight:700>with</span> <span style=color:#0086b3>open</span>(os<span style=color:#000;font-weight:700>.</span>path<span style=color:#000;font-weight:700>.</span>join(root, file)) <span style=color:#000;font-weight:700>as</span> i:
</span></span><span style=display:flex><span>                content<span style=color:#000;font-weight:700>.</span>append(i<span style=color:#000;font-weight:700>.</span>read())
</span></span><span style=display:flex><span>                label<span style=color:#000;font-weight:700>.</span>append(topic)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#998;font-style:italic># running the k-means for 32 clusters</span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># creating tf-idf matrix</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tfidf_matrix_constructor <span style=color:#000;font-weight:700>=</span> TfidfVectorizer(max_df<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.8</span>, max_features<span style=color:#000;font-weight:700>=</span><span style=color:#099>200000</span>, min_df<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.2</span>, ngram_range<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>1</span>,<span style=color:#099>3</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tfidf_matrix <span style=color:#000;font-weight:700>=</span> tfidf_matrix_constructor<span style=color:#000;font-weight:700>.</span>fit_transform(content)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># printing the shape of the resultant matrix to ensure I am right</span>
</span></span><span style=display:flex><span><span style=color:#0086b3>print</span>(tfidf_matrix<span style=color:#000;font-weight:700>.</span>shape)
</span></span></code></pre></div><pre><code>(9986, 59)
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#998;font-style:italic># now applying k-means for range 1-32 and calculating silhouette_score for each cluster</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>for</span> k <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>range</span>(<span style=color:#099>2</span> ,<span style=color:#099>33</span>):
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># define k-means constructor</span>
</span></span><span style=display:flex><span>    kmeans <span style=color:#000;font-weight:700>=</span> KMeans(n_clusters<span style=color:#000;font-weight:700>=</span>k,random_state<span style=color:#000;font-weight:700>=</span><span style=color:#099>10</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    cluster_labels <span style=color:#000;font-weight:700>=</span> kmeans<span style=color:#000;font-weight:700>.</span>fit_predict(tfidf_matrix<span style=color:#000;font-weight:700>.</span>toarray())
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># Calculating silhouette_score for k</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    score <span style=color:#000;font-weight:700>=</span> silhouette_score(tfidf_matrix<span style=color:#000;font-weight:700>.</span>toarray(), cluster_labels, random_state<span style=color:#000;font-weight:700>=</span><span style=color:#099>10</span>)
</span></span><span style=display:flex><span>    <span style=color:#0086b3>print</span>(<span style=color:#d14>&#34;The silhouette score for </span><span style=color:#d14>{}</span><span style=color:#d14> clusters is </span><span style=color:#d14>{}</span><span style=color:#d14>&#34;</span><span style=color:#000;font-weight:700>.</span>format(k,score))
</span></span></code></pre></div><pre><code>The silhouette score for 2 clusters is 0.2092956601357311
The silhouette score for 3 clusters is 0.1463292693620873
The silhouette score for 4 clusters is 0.14046381676564526
The silhouette score for 5 clusters is 0.14694926636316893
The silhouette score for 6 clusters is 0.14478803184773398
The silhouette score for 7 clusters is 0.17189746569523418
The silhouette score for 8 clusters is 0.17280711786498046
The silhouette score for 9 clusters is 0.18248360175164505
The silhouette score for 10 clusters is 0.185809463489821
The silhouette score for 11 clusters is 0.19185632542163303
The silhouette score for 12 clusters is 0.19569188868141868
The silhouette score for 13 clusters is 0.19476772871615036
The silhouette score for 14 clusters is 0.20251183229887623
The silhouette score for 15 clusters is 0.19103405902025516
The silhouette score for 16 clusters is 0.19483617751124183
The silhouette score for 17 clusters is 0.19140067934731583
The silhouette score for 18 clusters is 0.19934328007322114
The silhouette score for 19 clusters is 0.19446860597424745
The silhouette score for 20 clusters is 0.19904443285585602
The silhouette score for 21 clusters is 0.195384733891542
The silhouette score for 22 clusters is 0.19990294699010308
The silhouette score for 23 clusters is 0.20434103038355314
The silhouette score for 24 clusters is 0.20162229208943913
The silhouette score for 25 clusters is 0.20001554425267193
The silhouette score for 26 clusters is 0.20297321222570094
The silhouette score for 27 clusters is 0.2023863657790054
The silhouette score for 28 clusters is 0.19960601038803405
The silhouette score for 29 clusters is 0.1985121190442007
The silhouette score for 30 clusters is 0.20256036983356498
The silhouette score for 31 clusters is 0.2001042315801357
The silhouette score for 32 clusters is 0.20251412402591076
</code></pre><p>So the higher the value of Silhouette Score, better the number of clusters.</p></div></article><button class=floating-button>
<a class=floating-button__link href=https://jdvala.github.io><span>home</span></a></button></div><footer class=post-footer><div class=footer><div>© 2020, Jay Vala. Theme - Origin by Andrey Parfenov</div><div class=footer__socials><a href=www.github.com/jdvala target=_blank class=social-link title="Github link" rel=noopener aria-label="follow on Github——Opens in a new window"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M0 0v24h24V0H0zm14.534 19.59c-.406.078-.534-.171-.534-.384v-2.195c0-.747-.262-1.233-.55-1.481 1.782-.198 3.654-.875 3.654-3.947.0-.874-.311-1.588-.824-2.147.083-.202.357-1.016-.079-2.117.0.0-.671-.215-2.198.82-.639-.18-1.323-.267-2.003-.271-.68.003-1.364.091-2.003.269-1.528-1.035-2.2-.82-2.2-.82-.434 1.102-.16 1.915-.077 2.118-.512.56-.824 1.273-.824 2.147.0 3.064 1.867 3.751 3.645 3.954-.229.2-.436.552-.508 1.07-.457.204-1.614.557-2.328-.666.0.0-.423-.768-1.227-.825.0.0-.78-.01-.055.487.0.0.525.246.889 1.17.0.0.463 1.428 2.688.944v1.489c0 .211-.129.459-.528.385C6.292 18.533 4 15.534 4 12c0-4.419 3.582-8 8-8s8 3.581 8 8c0 3.533-2.289 6.531-5.466 7.59z"/></svg></a></div></div></footer><script src=https://jdvala.github.io/js/script.js></script></body></html>