<!doctype html><html lang=en><head><meta charset=utf-8><title>Jay Vala</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A baseline for further expriments"><meta property="og:title" content="Latent Dirichlet Allocation (Topic Modelling) - BaseLine"><meta property="og:description" content="A baseline for further expriments"><meta property="og:type" content="website"><meta property="og:url" content="https://jdvala.github.io/posts/2018-05-27-latent-dirichlet-allocation-topic-modeling-baseline/"><meta itemprop=name content="Latent Dirichlet Allocation (Topic Modelling) - BaseLine"><meta itemprop=description content="A baseline for further expriments"><meta name=twitter:card content="summary"><meta name=twitter:title content="Latent Dirichlet Allocation (Topic Modelling) - BaseLine"><meta name=twitter:description content="A baseline for further expriments"><link rel=apple-touch-icon sizes=180x180 href=apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=favicon-32.png><link rel=stylesheet href=https://jdvala.github.io/scss/style.min.d1aa507e320f63a9a89fb4d16c025955cea1564900de1060a4b2d7cabbabcdec.css></head><body><header><div class="header header-frame"><div><h1 class=header__title>Latent Dirichlet Allocation (Topic Modelling) - BaseLine</h1><div class=header__description>A baseline for further expriments</div></div><nav class=header-nav><ul class="header-nav-list header-nav-list--menu"><li class=header-nav-list__item><a class=header-nav-list__link href=/about/><span>About</span></a></li></ul><button class=header-nav-list__nav-btn>navigation</button></nav><button class=mb-header__menu-btn>
<span class=mb-header__menu-btn-line></span><span class=mb-header__menu-btn-line></span><span class=mb-header__menu-btn-line></span></button></div><nav id=mobile-header-nav class=mb-header-nav><button class="mb-header-nav__close-btn flex-center"><svg class="mb-header-nav__svg-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="32" height="32"
            ><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"
                /><path d="M0 0h24v24H0z" fill="none" /></svg></button><div class=mb-header-nav__wrapper><div class=mb-header-nav__container><svg width="240" height="72" viewBox="0 0 240 72" class="mb-header-nav__title"
                ><text x="50%" y="50%" dominant-baseline="middle" text-anchor="middle">Tags</text></svg><ul class=mb-header-nav-list><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/python/>python</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/text/>text</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/dataset/>dataset</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/nlp/>nlp</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/analysis/>analysis</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/lda/>LDA</a></li><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=https://jdvala.github.io/tags/topic-modelling/>topic-modelling</a></li></ul></div><div class=mb-header-nav__container><svg width="240" height="72" viewBox="0 0 240 72" class="mb-header-nav__title"
                ><text x="50%" y="50%" dominant-baseline="middle" text-anchor="middle">Menu</text></svg><ul class=mb-header-nav-list><li class=mb-header-nav-list__item><a class=mb-header-nav-list__link href=/about/>About</a></li></ul></div></div></nav></header><div id=content><article class=post><div class=post-content><p>Topic modeling can be useful when having a large corpus, when we want to unearth the meaning or of the data we have, which is too large to be done manually.
In simple terms LDA is probabilistic unsupervised models that gives out top topics.
So suppose we have a set of documents. we’ve chosen some fixed number of K topics to discover, and want to use LDA to learn the topic representation of each document and the words associated to each topic. LDA uses collapsed Gibbs sampling. How?</p><ul><li><p>Go through each document, and randomly assign each word(w) in the document(d) to one of the K topics(t).</p></li><li><p>This random assignment already gives us topic assignment and the topic distribution but they won&rsquo;t be good at all.</p></li><li><p>So to importve upon them we have to,</p><ul><li>Go through every word in the document and compute two things<ul><li>p(topic t | document d), i.e. the words(w) in document d currently assgin to topic t.</li><li>p(word w | topic t), i.e. the assignment of topic over all the document because of this word(w).</li><li>This a generative model and hence we have to reassign a new topic to a word and repeat.</li></ul></li></ul></li></ul><p>To learn about it more and to get an intution behind the idea how LDA works <a href=http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/>click here</a> I got the intusion from there.</p><h3 id=steps>Steps</h3><ul><li>Pre-processing and training corpus creation</li><li>Building dictionary</li><li>Feature extraction</li><li>LDA model training</li></ul><p>Pre-processing text for LDA is a little bit different for LDA than what I did for RNN screated in this <a href=https://jdvala.github.io/blog.io/thesis/2018/05/23/Creating-Data-Set-Again-!.html>post</a>.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># Lets pre-process them.</span>
<span style=color:#000;font-weight:700>import</span> <span style=color:#555>os</span>
<span style=color:#000;font-weight:700>import</span> <span style=color:#555>random</span>
<span style=color:#000;font-weight:700>from</span> <span style=color:#555>nltk.corpus</span> <span style=color:#000;font-weight:700>import</span> stopwords
<span style=color:#000;font-weight:700>import</span> <span style=color:#555>string</span>
<span style=color:#000;font-weight:700>import</span> <span style=color:#555>sys</span>
<span style=color:#000;font-weight:700>import</span> <span style=color:#555>spacy</span>
<span style=color:#000;font-weight:700>import</span> <span style=color:#555>re</span>
<span style=color:#000;font-weight:700>import</span> <span style=color:#555>logging</span>
<span style=color:#000;font-weight:700>from</span> <span style=color:#555>gensim.models.ldamodel</span> <span style=color:#000;font-weight:700>import</span> LdaModel <span style=color:#000;font-weight:700>as</span> Lda
<span style=color:#000;font-weight:700>from</span> <span style=color:#555>gensim</span> <span style=color:#000;font-weight:700>import</span> corpora
</code></pre></div><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># NLP model from spacy</span>
nlp <span style=color:#000;font-weight:700>=</span> spacy<span style=color:#000;font-weight:700>.</span>load(<span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>en</span><span style=color:#d14>&#39;</span>)
</code></pre></div><p>+++&ndash;</p><h3 id=pre-processing-text>Pre-processing Text</h3><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>preprocess</span>(text):
    <span style=color:#d14></span><span style=color:#d14>&#34;&#34;&#34;</span><span style=color:#d14>Returns text after preprocessing</span><span style=color:#d14>
</span><span style=color:#d14></span><span style=color:#d14>    :params:list of text</span><span style=color:#d14>
</span><span style=color:#d14></span><span style=color:#d14>    :returns:list of text after manipulation</span><span style=color:#d14>&#34;&#34;&#34;</span>
    
    pun <span style=color:#000;font-weight:700>=</span> string<span style=color:#000;font-weight:700>.</span>punctuation<span style=color:#000;font-weight:700>+</span><span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>$€¥₹£|–</span><span style=color:#d14>&#39;</span>
    regex <span style=color:#000;font-weight:700>=</span> re<span style=color:#000;font-weight:700>.</span>compile(<span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>[</span><span style=color:#d14>%s</span><span style=color:#d14>]</span><span style=color:#d14>&#39;</span> <span style=color:#000;font-weight:700>%</span> re<span style=color:#000;font-weight:700>.</span>escape(string<span style=color:#000;font-weight:700>.</span>punctuation))
    punct <span style=color:#000;font-weight:700>=</span> <span style=color:#d14></span><span style=color:#d14>&#34;</span><span style=color:#d14> </span><span style=color:#d14>&#34;</span><span style=color:#000;font-weight:700>.</span>join([i <span style=color:#000;font-weight:700>for</span> i <span style=color:#000;font-weight:700>in</span> text<span style=color:#000;font-weight:700>.</span>lower()<span style=color:#000;font-weight:700>.</span>split() <span style=color:#000;font-weight:700>if</span> i<span style=color:#000;font-weight:700>.</span>split() <span style=color:#000;font-weight:700>not</span> <span style=color:#000;font-weight:700>in</span> pun<span style=color:#000;font-weight:700>.</span>split()])
    stop <span style=color:#000;font-weight:700>=</span> <span style=color:#d14></span><span style=color:#d14>&#34;</span><span style=color:#d14> </span><span style=color:#d14>&#34;</span><span style=color:#000;font-weight:700>.</span>join([i <span style=color:#000;font-weight:700>for</span> i <span style=color:#000;font-weight:700>in</span> punct<span style=color:#000;font-weight:700>.</span>lower()<span style=color:#000;font-weight:700>.</span>split() <span style=color:#000;font-weight:700>if</span> i <span style=color:#000;font-weight:700>not</span> <span style=color:#000;font-weight:700>in</span> stopwords<span style=color:#000;font-weight:700>.</span>words(<span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>english</span><span style=color:#d14>&#39;</span>)])
    digit <span style=color:#000;font-weight:700>=</span> re<span style=color:#000;font-weight:700>.</span>sub(<span style=color:#d14>r</span><span style=color:#d14>&#39;</span><span style=color:#d14>\</span><span style=color:#d14>d+</span><span style=color:#d14>&#39;</span>,<span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>&#39;</span>,stop)
    <span style=color:#998;font-style:italic># removing punct again</span>
    punct_ <span style=color:#000;font-weight:700>=</span> regex<span style=color:#000;font-weight:700>.</span>sub(<span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>&#39;</span>,digit)
    doc <span style=color:#000;font-weight:700>=</span> nlp(punct_)
    lam <span style=color:#000;font-weight:700>=</span> <span style=color:#d14></span><span style=color:#d14>&#34;</span><span style=color:#d14> </span><span style=color:#d14>&#34;</span><span style=color:#000;font-weight:700>.</span>join(word<span style=color:#000;font-weight:700>.</span>lemma_ <span style=color:#000;font-weight:700>for</span> word <span style=color:#000;font-weight:700>in</span> doc)
    x <span style=color:#000;font-weight:700>=</span> lam<span style=color:#000;font-weight:700>.</span>split()
    y <span style=color:#000;font-weight:700>=</span> [s <span style=color:#000;font-weight:700>for</span> s <span style=color:#000;font-weight:700>in</span> x <span style=color:#000;font-weight:700>if</span> <span style=color:#0086b3>len</span>(s) <span style=color:#000;font-weight:700>&gt;</span> <span style=color:#099>2</span>]
    <span style=color:#000;font-weight:700>return</span> y
</code></pre></div><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># Lets load text from every doc into a list </span>

document_list <span style=color:#000;font-weight:700>=</span> []

<span style=color:#000;font-weight:700>for</span> root, dirs, files <span style=color:#000;font-weight:700>in</span> os<span style=color:#000;font-weight:700>.</span>walk(<span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>/home/jay/Thesis_1/Data/Data_EN</span><span style=color:#d14>&#39;</span>):
    <span style=color:#000;font-weight:700>for</span> <span style=color:#0086b3>file</span> <span style=color:#000;font-weight:700>in</span> files:
        <span style=color:#000;font-weight:700>if</span> <span style=color:#0086b3>file</span> <span style=color:#000;font-weight:700>!=</span> <span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>log.txt</span><span style=color:#d14>&#39;</span>:
            <span style=color:#000;font-weight:700>with</span> <span style=color:#0086b3>open</span>(os<span style=color:#000;font-weight:700>.</span>path<span style=color:#000;font-weight:700>.</span>join(root, <span style=color:#0086b3>file</span>), <span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>r</span><span style=color:#d14>&#39;</span>) <span style=color:#000;font-weight:700>as</span> f:
                document_list<span style=color:#000;font-weight:700>.</span>append(f<span style=color:#000;font-weight:700>.</span>read())
</code></pre></div><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># Lets divide the documents into test and train set</span>
<span style=color:#998;font-style:italic># I am taking 20% of documents for test set, but before that lets just suffle it.</span>
random<span style=color:#000;font-weight:700>.</span>shuffle(document_list)
train <span style=color:#000;font-weight:700>=</span> document_list[<span style=color:#0086b3>round</span>(<span style=color:#0086b3>len</span>(document_list)<span style=color:#000;font-weight:700>*</span><span style=color:#000;font-weight:700>.</span><span style=color:#099>2</span>):]
test <span style=color:#000;font-weight:700>=</span> document_list[:<span style=color:#0086b3>round</span>(<span style=color:#0086b3>len</span>(document_list)<span style=color:#000;font-weight:700>*</span><span style=color:#000;font-weight:700>.</span><span style=color:#099>2</span>)]
</code></pre></div><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#0086b3>len</span>(train)
</code></pre></div><pre><code>3692
</code></pre><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># preprocess the training set</span>
cleaned <span style=color:#000;font-weight:700>=</span> [preprocess(doc) <span style=color:#000;font-weight:700>for</span> doc <span style=color:#000;font-weight:700>in</span> train]
</code></pre></div><p>++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++-</p><h3 id=dictionary-building>Dictionary Building</h3><p>For dictionary building gensim requires all the words in corpus. So lets create a list of words in dictionary</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># For building dictionary I will use gensim.</span>
<span style=color:#998;font-style:italic># Dictionary are nothing but every unique term with its unique id as we have already created for training RNNs.</span>
<span style=color:#998;font-style:italic># We can also create &#39;hashdictionary&#39; were it uses hashing algorithm which will increase speed, but I will not worry</span>
<span style=color:#998;font-style:italic># about it as my corpus is small</span>

dictionary <span style=color:#000;font-weight:700>=</span> corpora<span style=color:#000;font-weight:700>.</span>Dictionary(cleaned)
</code></pre></div><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#000;font-weight:700>print</span>(dictionary)
</code></pre></div><pre><code>Dictionary(19634 unique tokens: ['-PRON-', 'access', 'achieve', 'achievement', 'act']...)
</code></pre><p>Now that dictonary is created we need to filter out the dictonary, we will filter out the words that occur in less than 4 document and words that occur in more than 40% of the documents. We do this because these words do not contibute in the different themes and topics that are in the corpus.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># removing extremes</span>
dictionary<span style=color:#000;font-weight:700>.</span>filter_extremes(no_below<span style=color:#000;font-weight:700>=</span><span style=color:#099>4</span>, no_above<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.4</span>)
</code></pre></div><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#000;font-weight:700>print</span>(dictionary)
</code></pre></div><pre><code>Dictionary(8231 unique tokens: ['-PRON-', 'access', 'achieve', 'achievement', 'adapt']...)
</code></pre><p>++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++-</p><h3 id=feature-extraction>Feature Extraction</h3><p>Now that dictionary is created, moving on to the next step, extracting features. Gensim provides use to necessary tools to extract features out of the courpus.
Feature extraction is nothing but generating but the frequencies of all the words in the vocabulary for that particular word.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>doc_term_matrix <span style=color:#000;font-weight:700>=</span> [dictionary<span style=color:#000;font-weight:700>.</span>doc2bow(doc) <span style=color:#000;font-weight:700>for</span> doc <span style=color:#000;font-weight:700>in</span> cleaned]
</code></pre></div><p>+++++++++++++++++++++</p><h3 id=model-building>Model Building</h3><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># As I know that I have only 32 topics in the corpus, I will set the num_topic argument as 32</span>
<span style=color:#998;font-style:italic># To see the progress I added loggig as suggested in Gensim Tutorial </span>
logging<span style=color:#000;font-weight:700>.</span>basicConfig(format<span style=color:#000;font-weight:700>=</span><span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>%(asctime)s</span><span style=color:#d14> : </span><span style=color:#d14>%(levelname)s</span><span style=color:#d14> : </span><span style=color:#d14>%(message)s</span><span style=color:#d14>&#39;</span>, level<span style=color:#000;font-weight:700>=</span>logging<span style=color:#000;font-weight:700>.</span>INFO)

ldamodel <span style=color:#000;font-weight:700>=</span> Lda(doc_term_matrix, num_topics<span style=color:#000;font-weight:700>=</span><span style=color:#099>32</span>, id2word <span style=color:#000;font-weight:700>=</span> dictionary, passes<span style=color:#000;font-weight:700>=</span><span style=color:#099>50</span>, iterations<span style=color:#000;font-weight:700>=</span><span style=color:#099>500</span>)
</code></pre></div><pre><code>2018-05-28 18:52:24,623 : INFO : using symmetric alpha at 0.03125
2018-05-28 18:52:24,627 : INFO : using symmetric eta at 0.03125
2018-05-28 18:52:24,631 : INFO : using serial LDA version on this node
2018-05-28 18:52:24,696 : INFO : running online (multi-pass) LDA training, 32 topics, 50 passes over the supplied corpus of 3692 documents, updating model once every 2000 documents, evaluating perplexity every 3692 documents, iterating 500x with a convergence threshold of 0.001000
2018-05-28 18:52:24,698 : INFO : PROGRESS: pass 0, at document #2000/3692
2018-05-28 18:53:04,688 : INFO : merging changes from 2000 documents into a model of 3692 documents
2018-05-28 18:53:04,760 : INFO : topic #14 (0.031): 0.013*&quot;research&quot; + 0.010*&quot;innovation&quot; + 0.009*&quot;sector&quot; + 0.007*&quot;protection&quot; + 0.007*&quot;woman&quot; + 0.006*&quot;europe&quot; + 0.006*&quot;medium&quot; + 0.005*&quot;content&quot; + 0.005*&quot;financial&quot; + 0.005*&quot;interactive&quot;
2018-05-28 18:53:04,763 : INFO : topic #1 (0.031): 0.007*&quot;person&quot; + 0.007*&quot;directive&quot; + 0.006*&quot;product&quot; + 0.006*&quot;right&quot; + 0.005*&quot;article&quot; + 0.005*&quot;request&quot; + 0.005*&quot;network&quot; + 0.004*&quot;law&quot; + 0.004*&quot;mercury&quot; + 0.004*&quot;agency&quot;
2018-05-28 18:53:04,764 : INFO : topic #29 (0.031): 0.009*&quot;research&quot; + 0.007*&quot;human&quot; + 0.007*&quot;right&quot; + 0.007*&quot;health&quot; + 0.006*&quot;directive&quot; + 0.005*&quot;employment&quot; + 0.005*&quot;animal&quot; + 0.005*&quot;law&quot; + 0.004*&quot;woman&quot; + 0.004*&quot;committee&quot;
2018-05-28 18:53:04,766 : INFO : topic #22 (0.031): 0.013*&quot;financial&quot; + 0.010*&quot;fund&quot; + 0.009*&quot;education&quot; + 0.006*&quot;directive&quot; + 0.005*&quot;strategy&quot; + 0.005*&quot;training&quot; + 0.004*&quot;instrument&quot; + 0.004*&quot;management&quot; + 0.004*&quot;nuclear&quot; + 0.004*&quot;safety&quot;
2018-05-28 18:53:04,768 : INFO : topic #3 (0.031): 0.023*&quot;passenger&quot; + 0.014*&quot;tax&quot; + 0.013*&quot;directive&quot; + 0.010*&quot;right&quot; + 0.008*&quot;air&quot; + 0.007*&quot;car&quot; + 0.007*&quot;travel&quot; + 0.007*&quot;carrier&quot; + 0.006*&quot;liability&quot; + 0.005*&quot;water&quot;
2018-05-28 18:53:04,769 : INFO : topic diff=18.296263, rho=1.000000
2018-05-28 18:53:22,841 : INFO : -7.718 per-word bound, 210.6 perplexity estimate based on a held-out corpus of 1692 documents with 605190 words
2018-05-28 18:53:22,843 : INFO : PROGRESS: pass 0, at document #3692/3692
2018-05-28 18:53:35,697 : INFO : merging changes from 1692 documents into a model of 3692 documents
2018-05-28 18:53:35,757 : INFO : topic #11 (0.031): 0.015*&quot;custom&quot; + 0.014*&quot;security&quot; + 0.009*&quot;directive&quot; + 0.009*&quot;control&quot; + 0.007*&quot;law&quot; + 0.006*&quot;trade&quot; + 0.006*&quot;document&quot; + 0.005*&quot;issue&quot; + 0.005*&quot;management&quot; + 0.005*&quot;common&quot;
2018-05-28 18:53:35,758 : INFO : topic #10 (0.031): 0.017*&quot;euro&quot; + 0.011*&quot;capital&quot; + 0.009*&quot;financial&quot; + 0.008*&quot;directive&quot; + 0.007*&quot;right&quot; + 0.007*&quot;pension&quot; + 0.007*&quot;coin&quot; + 0.006*&quot;company&quot; + 0.006*&quot;bank&quot; + 0.006*&quot;care&quot;
2018-05-28 18:53:35,760 : INFO : topic #1 (0.031): 0.013*&quot;person&quot; + 0.008*&quot;directive&quot; + 0.007*&quot;citizen&quot; + 0.007*&quot;network&quot; + 0.006*&quot;right&quot; + 0.006*&quot;sis&quot; + 0.006*&quot;contract&quot; + 0.006*&quot;request&quot; + 0.006*&quot;drug&quot; + 0.005*&quot;product&quot;
2018-05-28 18:53:35,762 : INFO : topic #18 (0.031): 0.010*&quot;directive&quot; + 0.007*&quot;application&quot; + 0.007*&quot;minor&quot; + 0.007*&quot;condition&quot; + 0.006*&quot;applicant&quot; + 0.006*&quot;air&quot; + 0.006*&quot;network&quot; + 0.005*&quot;lay&quot; + 0.005*&quot;import&quot; + 0.005*&quot;common&quot;
2018-05-28 18:53:35,764 : INFO : topic #26 (0.031): 0.015*&quot;treaty&quot; + 0.011*&quot;financial&quot; + 0.007*&quot;procedure&quot; + 0.006*&quot;progress&quot; + 0.006*&quot;acquis&quot; + 0.006*&quot;security&quot; + 0.005*&quot;court&quot; + 0.004*&quot;agreement&quot; + 0.004*&quot;rate&quot; + 0.004*&quot;government&quot;
2018-05-28 18:53:35,765 : INFO : topic diff=0.868584, rho=0.707107
2018-05-28 18:53:35,767 : INFO : PROGRESS: pass 1, at document #2000/3692
2018-05-28 18:53:47,128 : INFO : merging changes from 2000 documents into a model of 3692 documents
2018-05-28 18:53:47,218 : INFO : topic #28 (0.031): 0.026*&quot;right&quot; + 0.016*&quot;datum&quot; + 0.009*&quot;protection&quot; + 0.009*&quot;judicial&quot; + 0.008*&quot;justice&quot; + 0.007*&quot;directive&quot; + 0.007*&quot;treaty&quot; + 0.006*&quot;security&quot; + 0.006*&quot;fundamental&quot; + 0.006*&quot;matter&quot;
2018-05-28 18:53:47,222 : INFO : topic #24 (0.031): 0.020*&quot;general&quot; + 0.018*&quot;interest&quot; + 0.015*&quot;paper&quot; + 0.013*&quot;research&quot; + 0.013*&quot;medium&quot; + 0.010*&quot;green&quot; + 0.008*&quot;consultation&quot; + 0.008*&quot;sport&quot; + 0.007*&quot;organisation&quot; + 0.007*&quot;society&quot;
2018-05-28 18:53:47,225 : INFO : topic #11 (0.031): 0.018*&quot;custom&quot; + 0.015*&quot;security&quot; + 0.010*&quot;control&quot; + 0.008*&quot;directive&quot; + 0.007*&quot;trade&quot; + 0.007*&quot;document&quot; + 0.007*&quot;internal&quot; + 0.006*&quot;law&quot; + 0.006*&quot;management&quot; + 0.006*&quot;issue&quot;
2018-05-28 18:53:47,229 : INFO : topic #5 (0.031): 0.019*&quot;transport&quot; + 0.016*&quot;regional&quot; + 0.015*&quot;region&quot; + 0.015*&quot;vehicle&quot; + 0.011*&quot;fund&quot; + 0.010*&quot;road&quot; + 0.010*&quot;partnership&quot; + 0.009*&quot;initiative&quot; + 0.008*&quot;sea&quot; + 0.008*&quot;integration&quot;
2018-05-28 18:53:47,231 : INFO : topic #26 (0.031): 0.015*&quot;treaty&quot; + 0.012*&quot;financial&quot; + 0.007*&quot;procedure&quot; + 0.006*&quot;budgetary&quot; + 0.006*&quot;deficit&quot; + 0.006*&quot;progress&quot; + 0.006*&quot;rate&quot; + 0.006*&quot;court&quot; + 0.005*&quot;acquis&quot; + 0.005*&quot;government&quot;
2018-05-28 18:53:47,233 : INFO : topic diff=0.585917, rho=0.509912
2018-05-28 18:54:00,950 : INFO : -7.385 per-word bound, 167.2 perplexity estimate based on a held-out corpus of 1692 documents with 605190 words
2018-05-28 18:54:00,951 : INFO : PROGRESS: pass 1, at document #3692/3692
2018-05-28 18:54:10,696 : INFO : merging changes from 1692 documents into a model of 3692 documents
2018-05-28 18:54:10,778 : INFO : topic #31 (0.031): 0.020*&quot;progress&quot; + 0.018*&quot;accession&quot; + 0.016*&quot;candidate&quot; + 0.013*&quot;acquis&quot; + 0.010*&quot;environment&quot; + 0.009*&quot;turkey&quot; + 0.009*&quot;sec&quot; + 0.009*&quot;partnership&quot; + 0.009*&quot;priority&quot; + 0.008*&quot;negotiation&quot;
2018-05-28 18:54:10,780 : INFO : topic #3 (0.031): 0.024*&quot;directive&quot; + 0.024*&quot;passenger&quot; + 0.023*&quot;air&quot; + 0.021*&quot;transport&quot; + 0.021*&quot;tax&quot; + 0.012*&quot;carrier&quot; + 0.011*&quot;vehicle&quot; + 0.010*&quot;vat&quot; + 0.009*&quot;emission&quot; + 0.009*&quot;rail&quot;
2018-05-28 18:54:10,781 : INFO : topic #18 (0.031): 0.015*&quot;directive&quot; + 0.010*&quot;minor&quot; + 0.010*&quot;rail&quot; + 0.009*&quot;application&quot; + 0.008*&quot;condition&quot; + 0.008*&quot;interoperability&quot; + 0.008*&quot;network&quot; + 0.008*&quot;standard&quot; + 0.007*&quot;lay&quot; + 0.007*&quot;agency&quot;
2018-05-28 18:54:10,784 : INFO : topic #30 (0.031): 0.019*&quot;security&quot; + 0.012*&quot;border&quot; + 0.010*&quot;external&quot; + 0.008*&quot;migration&quot; + 0.007*&quot;defence&quot; + 0.007*&quot;strategy&quot; + 0.006*&quot;relation&quot; + 0.006*&quot;management&quot; + 0.006*&quot;crisis&quot; + 0.006*&quot;agreement&quot;
2018-05-28 18:54:10,785 : INFO : topic #29 (0.031): 0.017*&quot;research&quot; + 0.014*&quot;woman&quot; + 0.013*&quot;human&quot; + 0.012*&quot;right&quot; + 0.011*&quot;child&quot; + 0.010*&quot;health&quot; + 0.008*&quot;man&quot; + 0.007*&quot;equality&quot; + 0.006*&quot;scientific&quot; + 0.006*&quot;protection&quot;
2018-05-28 18:54:10,787 : INFO : topic diff=0.722667, rho=0.509912
2018-05-28 18:54:10,790 : INFO : PROGRESS: pass 2, at document #2000/3692
2018-05-28 18:54:21,708 : INFO : merging changes from 2000 documents into a model of 3692 documents
2018-05-28 18:54:21,815 : INFO : topic #27 (0.031): 0.018*&quot;datum&quot; + 0.010*&quot;access&quot; + 0.009*&quot;protection&quot; + 0.007*&quot;internet&quot; + 0.006*&quot;plan&quot; + 0.006*&quot;partner&quot; + 0.006*&quot;regional&quot; + 0.006*&quot;network&quot; + 0.006*&quot;transport&quot; + 0.005*&quot;asylum&quot;
2018-05-28 18:54:21,818 : INFO : topic #3 (0.031): 0.026*&quot;transport&quot; + 0.024*&quot;air&quot; + 0.023*&quot;directive&quot; + 0.023*&quot;passenger&quot; + 0.020*&quot;tax&quot; + 0.012*&quot;vehicle&quot; + 0.012*&quot;carrier&quot; + 0.010*&quot;rail&quot; + 0.009*&quot;vat&quot; + 0.009*&quot;emission&quot;
2018-05-28 18:54:21,819 : INFO : topic #31 (0.031): 0.022*&quot;progress&quot; + 0.019*&quot;accession&quot; + 0.017*&quot;candidate&quot; + 0.016*&quot;acquis&quot; + 0.011*&quot;turkey&quot; + 0.010*&quot;sec&quot; + 0.010*&quot;negotiation&quot; + 0.010*&quot;environment&quot; + 0.009*&quot;enlargement&quot; + 0.009*&quot;capacity&quot;
2018-05-28 18:54:21,820 : INFO : topic #14 (0.031): 0.025*&quot;research&quot; + 0.018*&quot;people&quot; + 0.018*&quot;innovation&quot; + 0.017*&quot;young&quot; + 0.016*&quot;youth&quot; + 0.014*&quot;cultural&quot; + 0.011*&quot;europe&quot; + 0.009*&quot;sector&quot; + 0.008*&quot;culture&quot; + 0.008*&quot;field&quot;
2018-05-28 18:54:21,822 : INFO : topic #18 (0.031): 0.017*&quot;directive&quot; + 0.013*&quot;rail&quot; + 0.011*&quot;interoperability&quot; + 0.010*&quot;network&quot; + 0.010*&quot;minor&quot; + 0.010*&quot;agency&quot; + 0.009*&quot;equipment&quot; + 0.008*&quot;application&quot; + 0.008*&quot;technical&quot; + 0.008*&quot;condition&quot;
2018-05-28 18:54:21,823 : INFO : topic diff=0.694411, rho=0.454264
2018-05-28 18:54:34,992 : INFO : -7.278 per-word bound, 155.2 perplexity estimate based on a held-out corpus of 1692 documents with 605190 words
2018-05-28 18:54:34,993 : INFO : PROGRESS: pass 2, at document #3692/3692
2018-05-28 18:54:43,851 : INFO : merging changes from 1692 documents into a model of 3692 documents
2018-05-28 18:54:43,920 : INFO : topic #20 (0.031): 0.022*&quot;trade&quot; + 0.011*&quot;agreement&quot; + 0.011*&quot;consumer&quot; + 0.010*&quot;committee&quot; + 0.009*&quot;standard&quot; + 0.008*&quot;sector&quot; + 0.007*&quot;product&quot; + 0.007*&quot;business&quot; + 0.007*&quot;legislation&quot; + 0.006*&quot;directive&quot;
2018-05-28 18:54:43,924 : INFO : topic #27 (0.031): 0.020*&quot;datum&quot; + 0.011*&quot;access&quot; + 0.010*&quot;protection&quot; + 0.007*&quot;plan&quot; + 0.007*&quot;internet&quot; + 0.006*&quot;network&quot; + 0.006*&quot;partner&quot; + 0.006*&quot;region&quot; + 0.006*&quot;regional&quot; + 0.006*&quot;instrument&quot;
2018-05-28 18:54:43,928 : INFO : topic #9 (0.031): 0.018*&quot;financial&quot; + 0.012*&quot;crime&quot; + 0.011*&quot;terrorist&quot; + 0.009*&quot;fraud&quot; + 0.009*&quot;prevention&quot; + 0.009*&quot;infrastructure&quot; + 0.009*&quot;combat&quot; + 0.008*&quot;noise&quot; + 0.008*&quot;terrorism&quot; + 0.008*&quot;money&quot;
2018-05-28 18:54:43,931 : INFO : topic #3 (0.031): 0.028*&quot;transport&quot; + 0.026*&quot;air&quot; + 0.023*&quot;directive&quot; + 0.022*&quot;passenger&quot; + 0.019*&quot;tax&quot; + 0.015*&quot;vehicle&quot; + 0.012*&quot;carrier&quot; + 0.011*&quot;vat&quot; + 0.011*&quot;duty&quot; + 0.009*&quot;emission&quot;
2018-05-28 18:54:43,937 : INFO : topic #13 (0.031): 0.041*&quot;directive&quot; + 0.019*&quot;law&quot; + 0.014*&quot;court&quot; + 0.013*&quot;right&quot; + 0.010*&quot;person&quot; + 0.010*&quot;legal&quot; + 0.009*&quot;proceeding&quot; + 0.008*&quot;eec&quot; + 0.008*&quot;worker&quot; + 0.008*&quot;case&quot;
2018-05-28 18:54:43,940 : INFO : topic diff=0.752502, rho=0.454264
2018-05-28 18:54:43,942 : INFO : PROGRESS: pass 3, at document #2000/3692
2018-05-28 18:54:54,499 : INFO : merging changes from 2000 documents into a model of 3692 documents
2018-05-28 18:54:54,594 : INFO : topic #18 (0.031): 0.020*&quot;directive&quot; + 0.016*&quot;rail&quot; + 0.013*&quot;interoperability&quot; + 0.013*&quot;agency&quot; + 0.012*&quot;equipment&quot; + 0.012*&quot;network&quot; + 0.011*&quot;technical&quot; + 0.010*&quot;minor&quot; + 0.009*&quot;railway&quot; + 0.009*&quot;condition&quot;
2018-05-28 18:54:54,595 : INFO : topic #12 (0.031): 0.027*&quot;fishing&quot; + 0.017*&quot;fishery&quot; + 0.012*&quot;committee&quot; + 0.011*&quot;vessel&quot; + 0.010*&quot;ecb&quot; + 0.010*&quot;bank&quot; + 0.009*&quot;humanitarian&quot; + 0.009*&quot;central&quot; + 0.008*&quot;group&quot; + 0.007*&quot;financial&quot;
2018-05-28 18:54:54,597 : INFO : topic #1 (0.031): 0.018*&quot;person&quot; + 0.012*&quot;contract&quot; + 0.010*&quot;citizen&quot; + 0.010*&quot;drug&quot; + 0.009*&quot;condition&quot; + 0.008*&quot;request&quot; + 0.008*&quot;network&quot; + 0.008*&quot;entry&quot; + 0.007*&quot;residence&quot; + 0.007*&quot;right&quot;
2018-05-28 18:54:54,598 : INFO : topic #4 (0.031): 0.019*&quot;right&quot; + 0.015*&quot;agreement&quot; + 0.014*&quot;europol&quot; + 0.013*&quot;online&quot; + 0.012*&quot;property&quot; + 0.012*&quot;patent&quot; + 0.012*&quot;protection&quot; + 0.011*&quot;intellectual&quot; + 0.010*&quot;access&quot; + 0.010*&quot;enforcement&quot;
2018-05-28 18:54:54,600 : INFO : topic #15 (0.031): 0.057*&quot;directive&quot; + 0.031*&quot;safety&quot; + 0.021*&quot;health&quot; + 0.018*&quot;risk&quot; + 0.014*&quot;worker&quot; + 0.013*&quot;eec&quot; + 0.010*&quot;exposure&quot; + 0.010*&quot;requirement&quot; + 0.010*&quot;protection&quot; + 0.009*&quot;convention&quot;
2018-05-28 18:54:54,602 : INFO : topic diff=0.675248, rho=0.413591
2018-05-28 18:55:07,337 : INFO : -7.219 per-word bound, 149.0 perplexity estimate based on a held-out corpus of 1692 documents with 605190 words
2018-05-28 18:55:07,339 : INFO : PROGRESS: pass 3, at document #3692/3692
2018-05-28 18:55:15,041 : INFO : merging changes from 1692 documents into a model of 3692 documents
2018-05-28 18:55:15,124 : INFO : topic #11 (0.031): 0.027*&quot;security&quot; + 0.021*&quot;custom&quot; + 0.015*&quot;control&quot; + 0.010*&quot;export&quot; + 0.009*&quot;document&quot; + 0.009*&quot;internal&quot; + 0.008*&quot;common&quot; + 0.007*&quot;trade&quot; + 0.007*&quot;management&quot; + 0.007*&quot;issue&quot;
2018-05-28 18:55:15,127 : INFO : topic #6 (0.031): 0.037*&quot;product&quot; + 0.029*&quot;food&quot; + 0.020*&quot;consumer&quot; + 0.014*&quot;agency&quot; + 0.014*&quot;health&quot; + 0.007*&quot;foodstuff&quot; + 0.007*&quot;name&quot; + 0.007*&quot;application&quot; + 0.007*&quot;modify&quot; + 0.006*&quot;agricultural&quot;
2018-05-28 18:55:15,129 : INFO : topic #20 (0.031): 0.026*&quot;trade&quot; + 0.013*&quot;consumer&quot; + 0.011*&quot;agreement&quot; + 0.010*&quot;committee&quot; + 0.010*&quot;standard&quot; + 0.008*&quot;sector&quot; + 0.008*&quot;business&quot; + 0.007*&quot;legislation&quot; + 0.007*&quot;product&quot; + 0.006*&quot;access&quot;
2018-05-28 18:55:15,131 : INFO : topic #3 (0.031): 0.033*&quot;transport&quot; + 0.027*&quot;air&quot; + 0.022*&quot;passenger&quot; + 0.022*&quot;directive&quot; + 0.018*&quot;vehicle&quot; + 0.017*&quot;tax&quot; + 0.012*&quot;carrier&quot; + 0.011*&quot;duty&quot; + 0.011*&quot;vat&quot; + 0.010*&quot;airport&quot;
2018-05-28 18:55:15,133 : INFO : topic #25 (0.031): 0.073*&quot;aid&quot; + 0.023*&quot;competition&quot; + 0.018*&quot;article&quot; + 0.012*&quot;treaty&quot; + 0.012*&quot;grant&quot; + 0.009*&quot;agreement&quot; + 0.009*&quot;guideline&quot; + 0.009*&quot;sector&quot; + 0.008*&quot;application&quot; + 0.008*&quot;investment&quot;
2018-05-28 18:55:15,134 : INFO : topic diff=0.667393, rho=0.413591
2018-05-28 18:55:15,136 : INFO : PROGRESS: pass 4, at document #2000/3692
2018-05-28 18:55:23,624 : INFO : merging changes from 2000 documents into a model of 3692 documents
2018-05-28 18:55:23,720 : INFO : topic #22 (0.031): 0.030*&quot;fund&quot; + 0.022*&quot;financial&quot; + 0.017*&quot;education&quot; + 0.016*&quot;training&quot; + 0.015*&quot;project&quot; + 0.011*&quot;eur&quot; + 0.011*&quot;assistance&quot; + 0.011*&quot;period&quot; + 0.011*&quot;million&quot; + 0.010*&quot;instrument&quot;
2018-05-28 18:55:23,723 : INFO : topic #3 (0.031): 0.035*&quot;transport&quot; + 0.028*&quot;air&quot; + 0.022*&quot;passenger&quot; + 0.021*&quot;directive&quot; + 0.019*&quot;vehicle&quot; + 0.016*&quot;tax&quot; + 0.012*&quot;carrier&quot; + 0.010*&quot;airport&quot; + 0.010*&quot;duty&quot; + 0.009*&quot;vat&quot;
2018-05-28 18:55:23,726 : INFO : topic #9 (0.031): 0.020*&quot;financial&quot; + 0.017*&quot;crime&quot; + 0.012*&quot;terrorist&quot; + 0.011*&quot;prevention&quot; + 0.010*&quot;combat&quot; + 0.010*&quot;fraud&quot; + 0.010*&quot;terrorism&quot; + 0.009*&quot;infrastructure&quot; + 0.009*&quot;noise&quot; + 0.008*&quot;fight&quot;
2018-05-28 18:55:23,731 : INFO : topic #23 (0.031): 0.036*&quot;convention&quot; + 0.035*&quot;maritime&quot; + 0.031*&quot;ship&quot; + 0.019*&quot;sea&quot; + 0.018*&quot;port&quot; + 0.017*&quot;pollution&quot; + 0.016*&quot;vessel&quot; + 0.015*&quot;marine&quot; + 0.012*&quot;party&quot; + 0.012*&quot;protocol&quot;
2018-05-28 18:55:23,735 : INFO : topic #1 (0.031): 0.019*&quot;person&quot; + 0.013*&quot;contract&quot; + 0.011*&quot;citizen&quot; + 0.011*&quot;drug&quot; + 0.010*&quot;condition&quot; + 0.008*&quot;entry&quot; + 0.008*&quot;residence&quot; + 0.008*&quot;network&quot; + 0.008*&quot;request&quot; + 0.007*&quot;right&quot;
2018-05-28 18:55:23,741 : INFO : topic diff=0.576249, rho=0.382192
2018-05-28 18:55:37,283 : INFO : -7.182 per-word bound, 145.2 perplexity estimate based on a held-out corpus of 1692 documents with 605190 words
2018-05-28 18:55:37,284 : INFO : PROGRESS: pass 4, at document #3692/3692
2018-05-28 18:55:45,100 : INFO : merging changes from 1692 documents into a model of 3692 documents
2018-05-28 18:55:45,188 : INFO : topic #2 (0.031): 0.028*&quot;animal&quot; + 0.027*&quot;product&quot; + 0.019*&quot;directive&quot; + 0.013*&quot;control&quot; + 0.012*&quot;material&quot; + 0.011*&quot;substance&quot; + 0.011*&quot;waste&quot; + 0.009*&quot;article&quot; + 0.008*&quot;import&quot; + 0.008*&quot;eec&quot;
2018-05-28 18:55:45,191 : INFO : topic #30 (0.031): 0.019*&quot;security&quot; + 0.011*&quot;external&quot; + 0.010*&quot;strategy&quot; + 0.009*&quot;border&quot; + 0.008*&quot;migration&quot; + 0.008*&quot;relation&quot; + 0.008*&quot;management&quot; + 0.007*&quot;defence&quot; + 0.007*&quot;political&quot; + 0.007*&quot;crisis&quot;
2018-05-28 18:55:45,193 : INFO : topic #22 (0.031): 0.031*&quot;fund&quot; + 0.023*&quot;financial&quot; + 0.016*&quot;education&quot; + 0.016*&quot;training&quot; + 0.015*&quot;project&quot; + 0.011*&quot;eur&quot; + 0.011*&quot;assistance&quot; + 0.011*&quot;million&quot; + 0.011*&quot;period&quot; + 0.011*&quot;instrument&quot;
2018-05-28 18:55:45,194 : INFO : topic #19 (0.031): 0.066*&quot;energy&quot; + 0.017*&quot;emission&quot; + 0.016*&quot;environmental&quot; + 0.014*&quot;gas&quot; + 0.010*&quot;electricity&quot; + 0.010*&quot;directive&quot; + 0.010*&quot;renewable&quot; + 0.009*&quot;source&quot; + 0.009*&quot;climate&quot; + 0.009*&quot;efficiency&quot;
2018-05-28 18:55:45,196 : INFO : topic #29 (0.031): 0.020*&quot;woman&quot; + 0.018*&quot;human&quot; + 0.018*&quot;child&quot; + 0.017*&quot;right&quot; + 0.014*&quot;equal&quot; + 0.012*&quot;health&quot; + 0.012*&quot;research&quot; + 0.011*&quot;equality&quot; + 0.011*&quot;discrimination&quot; + 0.011*&quot;man&quot;
2018-05-28 18:55:45,197 : INFO : topic diff=0.544776, rho=0.382192
2018-05-28 18:55:45,199 : INFO : PROGRESS: pass 5, at document #2000/3692
2018-05-28 18:55:54,388 : INFO : merging changes from 2000 documents into a model of 3692 documents
2018-05-28 18:55:54,467 : INFO : topic #11 (0.031): 0.028*&quot;security&quot; + 0.019*&quot;custom&quot; + 0.018*&quot;control&quot; + 0.010*&quot;internal&quot; + 0.010*&quot;export&quot; + 0.009*&quot;document&quot; + 0.009*&quot;electronic&quot; + 0.008*&quot;common&quot; + 0.008*&quot;management&quot; + 0.007*&quot;audit&quot;
2018-05-28 18:55:54,470 : INFO : topic #28 (0.031): 0.026*&quot;right&quot; + 0.019*&quot;datum&quot; + 0.016*&quot;justice&quot; + 0.013*&quot;judicial&quot; + 0.013*&quot;protection&quot; + 0.011*&quot;criminal&quot; + 0.010*&quot;freedom&quot; + 0.009*&quot;crime&quot; + 0.009*&quot;fundamental&quot; + 0.008*&quot;matter&quot;
2018-05-28 18:55:54,472 : INFO : topic #12 (0.031): 0.031*&quot;fishing&quot; + 0.028*&quot;fishery&quot; + 0.018*&quot;committee&quot; + 0.013*&quot;vessel&quot; + 0.011*&quot;ecb&quot; + 0.010*&quot;fish&quot; + 0.010*&quot;bank&quot; + 0.009*&quot;group&quot; + 0.009*&quot;central&quot; + 0.009*&quot;board&quot;
2018-05-28 18:55:54,475 : INFO : topic #15 (0.031): 0.060*&quot;directive&quot; + 0.039*&quot;safety&quot; + 0.030*&quot;health&quot; + 0.021*&quot;risk&quot; + 0.015*&quot;worker&quot; + 0.013*&quot;eec&quot; + 0.012*&quot;protection&quot; + 0.010*&quot;exposure&quot; + 0.010*&quot;requirement&quot; + 0.010*&quot;nuclear&quot;
2018-05-28 18:55:54,478 : INFO : topic #4 (0.031): 0.026*&quot;right&quot; + 0.016*&quot;agreement&quot; + 0.015*&quot;property&quot; + 0.015*&quot;protection&quot; + 0.015*&quot;online&quot; + 0.014*&quot;europol&quot; + 0.013*&quot;intellectual&quot; + 0.013*&quot;patent&quot; + 0.011*&quot;copyright&quot; + 0.011*&quot;enforcement&quot;
2018-05-28 18:55:54,482 : INFO : topic diff=0.467382, rho=0.357006
2018-05-28 18:56:07,223 : INFO : -7.157 per-word bound, 142.7 perplexity estimate based on a held-out corpus of 1692 documents with 605190 words
2018-05-28 18:56:07,224 : INFO : PROGRESS: pass 5, at document #3692/3692
2018-05-28 18:56:15,141 : INFO : merging changes from 1692 documents into a model of 3692 documents
2018-05-28 18:56:15,234 : INFO : topic #9 (0.031): 0.020*&quot;financial&quot; + 0.020*&quot;crime&quot; + 0.012*&quot;terrorist&quot; + 0.012*&quot;combat&quot; + 0.011*&quot;prevention&quot; + 0.010*&quot;fraud&quot; + 0.010*&quot;terrorism&quot; + 0.009*&quot;money&quot; + 0.009*&quot;fight&quot; + 0.008*&quot;organise&quot;
2018-05-28 18:56:15,236 : INFO : topic #19 (0.031): 0.067*&quot;energy&quot; + 0.018*&quot;emission&quot; + 0.017*&quot;environmental&quot; + 0.014*&quot;gas&quot; + 0.011*&quot;electricity&quot; + 0.010*&quot;directive&quot; + 0.010*&quot;renewable&quot; + 0.010*&quot;source&quot; + 0.009*&quot;climate&quot; + 0.009*&quot;efficiency&quot;
2018-05-28 18:56:15,238 : INFO : topic #28 (0.031): 0.026*&quot;right&quot; + 0.018*&quot;datum&quot; + 0.017*&quot;justice&quot; + 0.013*&quot;judicial&quot; + 0.013*&quot;protection&quot; + 0.011*&quot;criminal&quot; + 0.011*&quot;freedom&quot; + 0.009*&quot;fundamental&quot; + 0.009*&quot;crime&quot; + 0.008*&quot;police&quot;
2018-05-28 18:56:15,240 : INFO : topic #5 (0.031): 0.036*&quot;regional&quot; + 0.031*&quot;region&quot; + 0.030*&quot;transport&quot; + 0.014*&quot;partnership&quot; + 0.013*&quot;network&quot; + 0.012*&quot;infrastructure&quot; + 0.012*&quot;integration&quot; + 0.011*&quot;partner&quot; + 0.010*&quot;road&quot; + 0.010*&quot;sea&quot;
2018-05-28 18:56:15,242 : INFO : topic #23 (0.031): 0.044*&quot;convention&quot; + 0.036*&quot;maritime&quot; + 0.032*&quot;ship&quot; + 0.020*&quot;sea&quot; + 0.019*&quot;port&quot; + 0.017*&quot;pollution&quot; + 0.015*&quot;marine&quot; + 0.015*&quot;vessel&quot; + 0.014*&quot;party&quot; + 0.014*&quot;protocol&quot;
2018-05-28 18:56:15,244 : INFO : topic diff=0.434388, rho=0.357006
2018-05-28 18:56:15,246 : INFO : PROGRESS: pass 6, at document #2000/3692
2018-05-28 18:56:25,687 : INFO : merging changes from 2000 documents into a model of 3692 documents
2018-05-28 18:56:25,775 : INFO : topic #4 (0.031): 0.029*&quot;right&quot; + 0.017*&quot;property&quot; + 0.017*&quot;protection&quot; + 0.016*&quot;agreement&quot; + 0.015*&quot;online&quot; + 0.014*&quot;intellectual&quot; + 0.014*&quot;europol&quot; + 0.013*&quot;patent&quot; + 0.012*&quot;copyright&quot; + 0.011*&quot;enforcement&quot;
2018-05-28 18:56:25,779 : INFO : topic #11 (0.031): 0.029*&quot;security&quot; + 0.019*&quot;control&quot; + 0.018*&quot;custom&quot; + 0.010*&quot;internal&quot; + 0.010*&quot;export&quot; + 0.010*&quot;electronic&quot; + 0.010*&quot;document&quot; + 0.008*&quot;common&quot; + 0.008*&quot;management&quot; + 0.007*&quot;audit&quot;
2018-05-28 18:56:25,785 : INFO : topic #7 (0.031): 0.038*&quot;custom&quot; + 0.036*&quot;tax&quot; + 0.028*&quot;request&quot; + 0.020*&quot;assistance&quot; + 0.018*&quot;taxation&quot; + 0.015*&quot;agreement&quot; + 0.013*&quot;legislation&quot; + 0.011*&quot;administrative&quot; + 0.010*&quot;party&quot; + 0.010*&quot;mutual&quot;
2018-05-28 18:56:25,786 : INFO : topic #6 (0.031): 0.045*&quot;product&quot; + 0.035*&quot;food&quot; + 0.020*&quot;consumer&quot; + 0.013*&quot;health&quot; + 0.009*&quot;modify&quot; + 0.008*&quot;agricultural&quot; + 0.008*&quot;agency&quot; + 0.008*&quot;genetically&quot; + 0.008*&quot;foodstuff&quot; + 0.008*&quot;feed&quot;
2018-05-28 18:56:25,788 : INFO : topic #8 (0.031): 0.033*&quot;acquis&quot; + 0.027*&quot;legislation&quot; + 0.025*&quot;progress&quot; + 0.017*&quot;accession&quot; + 0.014*&quot;field&quot; + 0.012*&quot;law&quot; + 0.011*&quot;note&quot; + 0.011*&quot;november&quot; + 0.011*&quot;effort&quot; + 0.011*&quot;sector&quot;
2018-05-28 18:56:25,790 : INFO : topic diff=0.374680, rho=0.336222
2018-05-28 18:56:38,800 : INFO : -7.138 per-word bound, 140.9 perplexity estimate based on a held-out corpus of 1692 documents with 605190 words
......
2018-05-28 19:15:44,378 : INFO : topic diff=0.019104, rho=0.140240
2018-05-28 19:15:44,381 : INFO : PROGRESS: pass 49, at document #2000/3692
2018-05-28 19:15:53,096 : INFO : merging changes from 2000 documents into a model of 3692 documents
2018-05-28 19:15:53,189 : INFO : topic #18 (0.031): 0.056*&quot;directive&quot; + 0.042*&quot;agency&quot; + 0.021*&quot;railway&quot; + 0.021*&quot;safety&quot; + 0.018*&quot;infrastructure&quot; + 0.016*&quot;network&quot; + 0.016*&quot;technical&quot; + 0.016*&quot;equipment&quot; + 0.016*&quot;requirement&quot; + 0.015*&quot;rail&quot;
2018-05-28 19:15:53,192 : INFO : topic #16 (0.031): 0.018*&quot;sector&quot; + 0.012*&quot;propose&quot; + 0.012*&quot;europe&quot; + 0.011*&quot;would&quot; + 0.008*&quot;increase&quot; + 0.008*&quot;could&quot; + 0.008*&quot;industry&quot; + 0.008*&quot;future&quot; + 0.007*&quot;change&quot; + 0.007*&quot;therefore&quot;
2018-05-28 19:15:53,195 : INFO : topic #1 (0.031): 0.027*&quot;person&quot; + 0.014*&quot;right&quot; + 0.013*&quot;citizen&quot; + 0.013*&quot;condition&quot; + 0.013*&quot;residence&quot; + 0.012*&quot;application&quot; + 0.012*&quot;noneu&quot; + 0.012*&quot;visa&quot; + 0.012*&quot;document&quot; + 0.011*&quot;entry&quot;
2018-05-28 19:15:53,198 : INFO : topic #26 (0.031): 0.033*&quot;treaty&quot; + 0.022*&quot;article&quot; + 0.011*&quot;euro&quot; + 0.010*&quot;procedure&quot; + 0.010*&quot;central&quot; + 0.009*&quot;rate&quot; + 0.009*&quot;bank&quot; + 0.009*&quot;government&quot; + 0.009*&quot;deficit&quot; + 0.009*&quot;budgetary&quot;
2018-05-28 19:15:53,203 : INFO : topic #29 (0.031): 0.028*&quot;right&quot; + 0.025*&quot;woman&quot; + 0.024*&quot;child&quot; + 0.021*&quot;human&quot; + 0.018*&quot;equal&quot; + 0.014*&quot;equality&quot; + 0.014*&quot;discrimination&quot; + 0.013*&quot;man&quot; + 0.011*&quot;gender&quot; + 0.011*&quot;combat&quot;
2018-05-28 19:15:53,207 : INFO : topic diff=0.018864, rho=0.138881
2018-05-28 19:16:05,395 : INFO : -7.047 per-word bound, 132.3 perplexity estimate based on a held-out corpus of 1692 documents with 605190 words
2018-05-28 19:16:05,396 : INFO : PROGRESS: pass 49, at document #3692/3692
2018-05-28 19:16:11,532 : INFO : merging changes from 1692 documents into a model of 3692 documents
2018-05-28 19:16:11,610 : INFO : topic #20 (0.031): 0.033*&quot;trade&quot; + 0.032*&quot;consumer&quot; + 0.014*&quot;standard&quot; + 0.010*&quot;business&quot; + 0.010*&quot;legislation&quot; + 0.008*&quot;practice&quot; + 0.007*&quot;access&quot; + 0.007*&quot;protection&quot; + 0.007*&quot;barrier&quot; + 0.006*&quot;internal&quot;
2018-05-28 19:16:11,612 : INFO : topic #26 (0.031): 0.034*&quot;treaty&quot; + 0.022*&quot;article&quot; + 0.011*&quot;euro&quot; + 0.010*&quot;procedure&quot; + 0.009*&quot;central&quot; + 0.009*&quot;rate&quot; + 0.009*&quot;government&quot; + 0.009*&quot;bank&quot; + 0.009*&quot;deficit&quot; + 0.009*&quot;budgetary&quot;
2018-05-28 19:16:11,615 : INFO : topic #10 (0.031): 0.035*&quot;financial&quot; + 0.026*&quot;company&quot; + 0.024*&quot;euro&quot; + 0.021*&quot;directive&quot; + 0.018*&quot;bank&quot; + 0.017*&quot;payment&quot; + 0.016*&quot;capital&quot; + 0.012*&quot;credit&quot; + 0.012*&quot;account&quot; + 0.010*&quot;institution&quot;
2018-05-28 19:16:11,617 : INFO : topic #22 (0.031): 0.043*&quot;fund&quot; + 0.029*&quot;financial&quot; + 0.020*&quot;project&quot; + 0.017*&quot;million&quot; + 0.016*&quot;eur&quot; + 0.016*&quot;assistance&quot; + 0.015*&quot;budget&quot; + 0.015*&quot;period&quot; + 0.014*&quot;instrument&quot; + 0.011*&quot;finance&quot;
2018-05-28 19:16:11,619 : INFO : topic #11 (0.031): 0.048*&quot;security&quot; + 0.023*&quot;control&quot; + 0.021*&quot;border&quot; + 0.017*&quot;defence&quot; + 0.012*&quot;internal&quot; + 0.012*&quot;common&quot; + 0.012*&quot;management&quot; + 0.011*&quot;export&quot; + 0.011*&quot;military&quot; + 0.011*&quot;external&quot;
2018-05-28 19:16:11,621 : INFO : topic diff=0.018733, rho=0.138881
</code></pre><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># Print topics</span>
<span style=color:#998;font-style:italic># I also know that none of my topic is more than 5 words i will set the num_words argument to 5</span>
<span style=color:#000;font-weight:700>for</span> i,topic <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>enumerate</span>(ldamodel<span style=color:#000;font-weight:700>.</span>print_topics(num_topics<span style=color:#000;font-weight:700>=</span><span style=color:#099>32</span>, num_words<span style=color:#000;font-weight:700>=</span><span style=color:#099>5</span>)):
    words <span style=color:#000;font-weight:700>=</span> topic[<span style=color:#099>1</span>]<span style=color:#000;font-weight:700>.</span>split(<span style=color:#d14></span><span style=color:#d14>&#34;</span><span style=color:#d14>+</span><span style=color:#d14>&#34;</span>)
    <span style=color:#000;font-weight:700>print</span> (words,<span style=color:#d14></span><span style=color:#d14>&#34;</span><span style=color:#d14>\n</span><span style=color:#d14>&#34;</span>)
</code></pre></div><pre><code>['0.045*&quot;employment&quot; ', ' 0.029*&quot;labour&quot; ', ' 0.019*&quot;worker&quot; ', ' 0.017*&quot;job&quot; ', ' 0.013*&quot;people&quot;'] 

['0.027*&quot;person&quot; ', ' 0.014*&quot;right&quot; ', ' 0.013*&quot;citizen&quot; ', ' 0.013*&quot;application&quot; ', ' 0.013*&quot;residence&quot;'] 

['0.043*&quot;directive&quot; ', ' 0.027*&quot;animal&quot; ', ' 0.015*&quot;eec&quot; ', ' 0.015*&quot;product&quot; ', ' 0.012*&quot;substance&quot;'] 

['0.071*&quot;transport&quot; ', ' 0.034*&quot;air&quot; ', ' 0.028*&quot;vehicle&quot; ', ' 0.027*&quot;passenger&quot; ', ' 0.022*&quot;road&quot;'] 

['0.066*&quot;right&quot; ', ' 0.034*&quot;property&quot; ', ' 0.026*&quot;protection&quot; ', ' 0.026*&quot;intellectual&quot; ', ' 0.017*&quot;copyright&quot;'] 

['0.051*&quot;region&quot; ', ' 0.044*&quot;regional&quot; ', ' 0.025*&quot;transport&quot; ', ' 0.019*&quot;network&quot; ', ' 0.016*&quot;cohesion&quot;'] 

['0.065*&quot;product&quot; ', ' 0.041*&quot;food&quot; ', ' 0.016*&quot;agricultural&quot; ', ' 0.011*&quot;consumer&quot; ', ' 0.010*&quot;label&quot;'] 

['0.061*&quot;tax&quot; ', ' 0.059*&quot;custom&quot; ', ' 0.029*&quot;duty&quot; ', ' 0.025*&quot;taxation&quot; ', ' 0.024*&quot;request&quot;'] 

['0.034*&quot;acquis&quot; ', ' 0.027*&quot;progress&quot; ', ' 0.026*&quot;legislation&quot; ', ' 0.020*&quot;accession&quot; ', ' 0.013*&quot;law&quot;'] 

['0.026*&quot;crime&quot; ', ' 0.021*&quot;criminal&quot; ', ' 0.016*&quot;combat&quot; ', ' 0.013*&quot;offence&quot; ', ' 0.012*&quot;europol&quot;'] 

['0.035*&quot;financial&quot; ', ' 0.026*&quot;company&quot; ', ' 0.024*&quot;euro&quot; ', ' 0.021*&quot;directive&quot; ', ' 0.018*&quot;bank&quot;'] 

['0.048*&quot;security&quot; ', ' 0.023*&quot;control&quot; ', ' 0.021*&quot;border&quot; ', ' 0.017*&quot;defence&quot; ', ' 0.012*&quot;internal&quot;'] 

['0.035*&quot;fishery&quot; ', ' 0.033*&quot;committee&quot; ', ' 0.029*&quot;fishing&quot; ', ' 0.016*&quot;vessel&quot; ', ' 0.016*&quot;statistic&quot;'] 

['0.038*&quot;directive&quot; ', ' 0.027*&quot;law&quot; ', ' 0.020*&quot;court&quot; ', ' 0.013*&quot;contract&quot; ', ' 0.013*&quot;legal&quot;'] 

['0.060*&quot;education&quot; ', ' 0.045*&quot;training&quot; ', ' 0.025*&quot;people&quot; ', ' 0.021*&quot;young&quot; ', ' 0.020*&quot;youth&quot;'] 

['0.063*&quot;health&quot; ', ' 0.047*&quot;safety&quot; ', ' 0.033*&quot;nuclear&quot; ', ' 0.030*&quot;risk&quot; ', ' 0.024*&quot;directive&quot;'] 

['0.018*&quot;sector&quot; ', ' 0.012*&quot;propose&quot; ', ' 0.012*&quot;europe&quot; ', ' 0.011*&quot;would&quot; ', ' 0.009*&quot;increase&quot;'] 

['0.027*&quot;research&quot; ', ' 0.024*&quot;strategy&quot; ', ' 0.015*&quot;innovation&quot; ', ' 0.014*&quot;plan&quot; ', ' 0.013*&quot;technology&quot;'] 

['0.056*&quot;directive&quot; ', ' 0.042*&quot;agency&quot; ', ' 0.021*&quot;safety&quot; ', ' 0.021*&quot;railway&quot; ', ' 0.019*&quot;infrastructure&quot;'] 

['0.082*&quot;energy&quot; ', ' 0.025*&quot;emission&quot; ', ' 0.022*&quot;environmental&quot; ', ' 0.017*&quot;gas&quot; ', ' 0.016*&quot;water&quot;'] 

['0.033*&quot;trade&quot; ', ' 0.032*&quot;consumer&quot; ', ' 0.014*&quot;standard&quot; ', ' 0.010*&quot;business&quot; ', ' 0.010*&quot;legislation&quot;'] 

['0.126*&quot;agreement&quot; ', ' 0.022*&quot;party&quot; ', ' 0.021*&quot;research&quot; ', ' 0.011*&quot;joint&quot; ', ' 0.011*&quot;part&quot;'] 

['0.043*&quot;fund&quot; ', ' 0.029*&quot;financial&quot; ', ' 0.020*&quot;project&quot; ', ' 0.017*&quot;million&quot; ', ' 0.016*&quot;eur&quot;'] 

['0.063*&quot;convention&quot; ', ' 0.038*&quot;maritime&quot; ', ' 0.033*&quot;ship&quot; ', ' 0.022*&quot;sea&quot; ', ' 0.019*&quot;port&quot;'] 

['0.027*&quot;paper&quot; ', ' 0.023*&quot;medium&quot; ', ' 0.022*&quot;audiovisual&quot; ', ' 0.022*&quot;green&quot; ', ' 0.020*&quot;general&quot;'] 

['0.080*&quot;aid&quot; ', ' 0.028*&quot;competition&quot; ', ' 0.019*&quot;article&quot; ', ' 0.013*&quot;grant&quot; ', ' 0.012*&quot;guideline&quot;'] 

['0.034*&quot;treaty&quot; ', ' 0.022*&quot;article&quot; ', ' 0.011*&quot;euro&quot; ', ' 0.010*&quot;procedure&quot; ', ' 0.009*&quot;central&quot;'] 

['0.062*&quot;datum&quot; ', ' 0.026*&quot;access&quot; ', ' 0.021*&quot;electronic&quot; ', ' 0.017*&quot;network&quot; ', ' 0.015*&quot;internet&quot;'] 

['0.025*&quot;right&quot; ', ' 0.023*&quot;justice&quot; ', ' 0.016*&quot;asylum&quot; ', ' 0.015*&quot;freedom&quot; ', ' 0.015*&quot;judicial&quot;'] 

['0.028*&quot;right&quot; ', ' 0.025*&quot;child&quot; ', ' 0.025*&quot;woman&quot; ', ' 0.021*&quot;human&quot; ', ' 0.019*&quot;equal&quot;'] 

['0.014*&quot;strategy&quot; ', ' 0.012*&quot;dialogue&quot; ', ' 0.011*&quot;security&quot; ', ' 0.011*&quot;partnership&quot; ', ' 0.010*&quot;political&quot;'] 

['0.033*&quot;progress&quot; ', ' 0.027*&quot;accession&quot; ', ' 0.024*&quot;candidate&quot; ', ' 0.023*&quot;acquis&quot; ', ' 0.016*&quot;turkey&quot;'] 
</code></pre><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#998;font-style:italic># Now lets save the model, dictonary, and corpus to use it for further use</span>
<span style=color:#998;font-style:italic># Saving Model</span>
ldamodel<span style=color:#000;font-weight:700>.</span>save(<span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>/home/jay/ANN_Models/LDA/LDA_Model</span><span style=color:#d14>&#39;</span>)

<span style=color:#998;font-style:italic># Saving Corpus</span>
<span style=color:#000;font-weight:700>import</span> <span style=color:#555>pickle</span>
<span style=color:#000;font-weight:700>with</span> <span style=color:#0086b3>open</span>(<span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>/home/jay/ANN_Models/LDA/LAD_Corpus.pickle</span><span style=color:#d14>&#39;</span>, <span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>wb</span><span style=color:#d14>&#39;</span>) <span style=color:#000;font-weight:700>as</span> p:
    pickle<span style=color:#000;font-weight:700>.</span>dump(cleaned,p)
    
<span style=color:#998;font-style:italic># Saving Dictonary</span>
dictionary<span style=color:#000;font-weight:700>.</span>save(<span style=color:#d14></span><span style=color:#d14>&#39;</span><span style=color:#d14>/home/jay/ANN_Models/LDA/LDA_Dictonary</span><span style=color:#d14>&#39;</span>)
</code></pre></div><pre><code>2018-05-28 19:17:04,097 : INFO : saving LdaState object under /home/jay/ANN_Models/LDA/LDA_Model.state, separately None
2018-05-28 19:17:04,111 : INFO : saved /home/jay/ANN_Models/LDA/LDA_Model.state
2018-05-28 19:17:04,120 : INFO : saving LdaModel object under /home/jay/ANN_Models/LDA/LDA_Model, separately ['expElogbeta', 'sstats']
2018-05-28 19:17:04,122 : INFO : storing np array 'expElogbeta' to /home/jay/ANN_Models/LDA/LDA_Model.expElogbeta.npy
2018-05-28 19:17:04,126 : INFO : not storing attribute id2word
2018-05-28 19:17:04,127 : INFO : not storing attribute state
2018-05-28 19:17:04,128 : INFO : not storing attribute dispatcher
2018-05-28 19:17:04,132 : INFO : saved /home/jay/ANN_Models/LDA/LDA_Model
2018-05-28 19:17:04,848 : INFO : saving Dictionary object under /home/jay/ANN_Models/LDA/LDA_Dictonary, separately None
2018-05-28 19:17:04,856 : INFO : saved /home/jay/ANN_Models/LDA/LDA_Dictonary
</code></pre><h3 id=notebooks>Notebooks</h3><p>You can view this notebook <a href=http://nbviewer.jupyter.org/github/jdvala/blog.io/blob/master/notebooks/Latent%20Dirichlet%20Allocation%20%28Topic%20Modeling%29%20-%20Baseline.ipynb>here</a></p></div></article><button class=floating-button>
<a class=floating-button__link href=https://jdvala.github.io><span>home</span></a></button></div><footer class=post-footer><div class=footer><div>© 2020, Jay Vala. Theme - Origin by Andrey Parfenov</div><div class=footer__socials><a href=www.github.com/jdvala target=_blank class=social-link title="Github link" rel=noopener aria-label="follow on Github——Opens in a new window"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M0 0v24h24V0H0zm14.534 19.59c-.406.078-.534-.171-.534-.384v-2.195c0-.747-.262-1.233-.55-1.481 1.782-.198 3.654-.875 3.654-3.947.0-.874-.311-1.588-.824-2.147.083-.202.357-1.016-.079-2.117.0.0-.671-.215-2.198.82-.639-.18-1.323-.267-2.003-.271-.68.003-1.364.091-2.003.269-1.528-1.035-2.2-.82-2.2-.82-.434 1.102-.16 1.915-.077 2.118-.512.56-.824 1.273-.824 2.147.0 3.064 1.867 3.751 3.645 3.954-.229.2-.436.552-.508 1.07-.457.204-1.614.557-2.328-.666.0.0-.423-.768-1.227-.825.0.0-.78-.01-.055.487.0.0.525.246.889 1.17.0.0.463 1.428 2.688.944v1.489c0 .211-.129.459-.528.385-3.18-1.057-5.472-4.056-5.472-7.59.0-4.419 3.582-8 8-8s8 3.581 8 8c0 3.533-2.289 6.531-5.466 7.59z"/></svg></a></div></div></footer><script src=https://jdvala.github.io/js/script.js></script></body></html>