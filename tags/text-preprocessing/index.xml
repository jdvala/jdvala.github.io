<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>text-preprocessing on Jay Vala</title><link>https://jdvala.github.io/tags/text-preprocessing/</link><description>Recent content in text-preprocessing on Jay Vala</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2020, Jay Vala. Theme - Origin by Andrey Parfenov</copyright><lastBuildDate>Fri, 11 May 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://jdvala.github.io/tags/text-preprocessing/index.xml" rel="self" type="application/rss+xml"/><item><title>German Text Preprocessing</title><link>https://jdvala.github.io/posts/2018-05-11-german-preprocessing/</link><pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate><guid>https://jdvala.github.io/posts/2018-05-11-german-preprocessing/</guid><description>Steps involved in preprocessing German Text German preprocessing of text is a little different than English text. There are special charaters with umlauts ä that should be converted first into its native form(&amp;lsquo;ä&amp;rsquo; to &amp;lsquo;ae&amp;rsquo;), this is a charater level replacement so it will need time.
import os, re, sys from nltk.corpus import stopwords german_stop_words = stopwords.words(&amp;#39;german&amp;#39;) german_stop_words[len(german_stop_words)-6] 'würden' As we can see that even the stop words have those umlauts so we need to convert those too</description></item><item><title>Converting HTML to Text</title><link>https://jdvala.github.io/posts/2018-05-10-html-to-text/</link><pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate><guid>https://jdvala.github.io/posts/2018-05-10-html-to-text/</guid><description>I have recently downloaded all the html files for German corpus text, and it take a lot of time to download those files, I did that to see all the html tags which helps me to device a strategy to to parse the text files further, same as in the post, Parsing EU Summaries.
So the main idea here is read all the html text and convert it into respective text file to further preprocess it.</description></item><item><title>English Corpus Preprocessing</title><link>https://jdvala.github.io/posts/2018-05-04-preprocessing-english-text/</link><pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate><guid>https://jdvala.github.io/posts/2018-05-04-preprocessing-english-text/</guid><description>Steps in preprocessing English text Before feeding text to any deep learning model it is advisable to preprocess the text to make it more suitable for the model. Preprocessing in general means cleaning the data to make it more convenient for any or all deep learning models to learn properly and efficiently.
Preprocessing is subjective, that means it depends on the purpose of preprocessing, depends on data, depends on language and also depends on the type of technique one would be adapting, but there are a lot of steps in preprocessing that does not depend on any of the above mentioned things, but its more of something that has to be done no matter what.</description></item></channel></rss>