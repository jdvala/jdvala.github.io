<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>word2vec on Jay Vala</title><link>https://jdvala.github.io/tags/word2vec/</link><description>Recent content in word2vec on Jay Vala</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2020, Jay Vala. Theme - Origin by Andrey Parfenov</copyright><lastBuildDate>Fri, 02 Nov 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://jdvala.github.io/tags/word2vec/index.xml" rel="self" type="application/rss+xml"/><item><title>NLP and ML notes</title><link>https://jdvala.github.io/posts/2018-11-02-basic-notes/</link><pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate><guid>https://jdvala.github.io/posts/2018-11-02-basic-notes/</guid><description>Notes: Natural Language Processing and Machine Learning Question: What are word embedding or what are word vectors?
Answer: Word embedding are learned representation for text where words that have the same meaning have a similar representation. Word embeddings are in fact a class of techniques where individual words are represented as real-valued vectors in a predefined vector space. Each word is mapped to one vector and the vector values are learned in a way that resembles a neural network, and hence the technique is often lumped into the field of deep learning.</description></item><item><title>Word Embedding and It's visualization</title><link>https://jdvala.github.io/posts/2018-05-05-word-embedding-and-visulization/</link><pubDate>Sat, 05 May 2018 00:00:00 +0000</pubDate><guid>https://jdvala.github.io/posts/2018-05-05-word-embedding-and-visulization/</guid><description>Word Embeddings and It&amp;rsquo;s visualizations Creating Word Vectors +++ In the last post I have obtained perfect text out of the EU summaries, now the goal is to create word embeddings out of it and visualizing them in tensorboard projector. I am visualizing it right now because I want to know how to do it because I will need to visualize bilingual word embeddings when I create one to see how well the bilingual word embeddings are so that I can fine tune the process to fit best for my case.</description></item></channel></rss>